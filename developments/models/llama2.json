[
    {
        "model": "meta-llama/Llama-2-7b-hf",
        "model_args": [
            "load_in_8bit=True"
        ],
        "memory_Gi": 64,
        "n_gpu": 1,
        "gpu_vram_gb": 16,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-7b-chat-hf",
        "model_args": [
            "load_in_8bit=True"
        ],
        "memory_Gi": 64,
        "n_gpu": 1,
        "gpu_vram_gb": 16,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-13b-hf",
        "model_args": [
            "load_in_8bit=True"
        ],
        "memory_Gi": 64,
        "n_gpu": 1,
        "gpu_vram_gb": 32,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-13b-chat-hf",
        "model_args": [
            "load_in_8bit=True"
        ],
        "memory_Gi": 64,
        "n_gpu": 1,
        "gpu_vram_gb": 32,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-70b-hf",
        "model_args": [
            "load_in_8bit=True"
        ],
        "memory_Gi": 128,
        "n_gpu": 1,
        "gpu_vram_gb": 80,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-70b-chat-hf",
        "model_args": [
            "load_in_8bit=True"
        ],
        "memory_Gi": 128,
        "n_gpu": 1,
        "gpu_vram_gb": 80,
        "require_hf_login": true
    }
]